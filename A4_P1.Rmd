---
title: "Assignment 4 - Coordinating Heart Rate"
author: "Katrine Tølbøll"
date: "November 6, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

## Analysing Heart Rate and Respiration data

The goal of this assignment is to first familiarize you with heart rate, and respiration data and their preprocessing. The second part explores how to analyze interpersonal coordination of these signals.

These are the questions you need to be able to answer at the end of the assignment (aka that you need to submit as part of the portfolio)

1) How do you preprocess heart rate and respiration data? Describe the process. If any data needs to be excluded, list the excluded data and motivate the exclusion.

Removing/handling artifacts (filtering away values that are too far away)
Downsampling ("smoothing" the timeseries so as to not have a billion data points)
Scale (subtracting the mean from the signal and dividing by the standard deviation to normalize the data)

2) Do you observe interpersonal coordination in heart rate and respiration? Describe your control baseline, the method used to quantify coordination, and the statistical models used to infer whether coordination was higher than in the baseline. Report the results of the models.

Different baselines: Shuffled or surrogate pairs 
Is there coordination at all?

3) Do you observe differences in coordination between conditions? Report the models and results.

Is there a difference between conditions? - Drop the baselines, do the real pairs, models that test the effect condition (the easy way) - fancier way: interaction vs real and baseline? 


4) Is respiration coordination a likely driver of heart rate coordination? Describe how you would test for it. Bonus points if you actually run the tests and report methods and results.



N.B. to give you a bit more data I included data from last year (Study1) and from your class (Study2). Note that synchronouns and turn-taking are the same across both studies, but the third condition is different: last year it was self-paced joint reading; this year it was the tv-series conversation. So you might want to exclude the self-paced reading (but, up to you!)

## Step by step suggestions to solve the assignment

### Exploring physiological signals

- Choose one pair (one pair, three conditions)
- Load the logs
- Produce a plot of the participants' respiration signal and a different one of the participants' HR signal (for inspecting whether the data is usable)
  N.B: remember the slides: artifacts, downsampling, scaling.
  N.B. The gridExtra::grid.arrange() function allows you to display the plots side by side. E.g. grid.arrange(plot1, plot2, plot3, ncol=3)
- Can you eye-ball which condition if any displays more physiological coordination?

- Run crqa on heart rate and respiration data (find parameters, run crqa)
- Does this tell you more than just eyeballing the plots?
  More recurrence on turn taking Resp than on conversation Resp woohoo

```{r}
library(pacman)
p_load(tidyverse, crqa, readr, groupdata2, gridExtra, stringr, lmerTest, MuMIn)

#reading all data from group 5
Sync1 = read_csv("CleanData/Study2_G5_T1_Synchronous.csv")
Turn1 = read_csv("CleanData/Study2_G5_T2_TurnTaking.csv")
Conv1 = read_csv("CleanData/Study2_G5_T3_Conversation.csv")


test = read.csv("CleanData/Study1_G1_T1_Synchronous.csv")

#premature plots just to see what we're working with
Sync1Resp1 = ggplot(Sync1, aes(time, Resp1)) + geom_line() + geom_line(aes(time, Resp2, color = "red"))
Sync1Resp1

Sync1HR1 = ggplot(Sync1, aes(time, HR1)) + geom_line() + geom_line(aes(time, HR2, color = "red"))
Sync1HR1 # det er noget pis

#Downsample
Sync  = Sync1 %>%    
  group(n= 100, method= 'greedy') %>%    
  dplyr::summarise(time= mean(time,na.rm=T), HR1 = mean(HR1,na.rm=T), HR2 = mean(HR2,na.rm=T), Resp1 =  mean(Resp1,na.rm=T), Resp2 = mean(Resp2,na.rm=T)) 

Turn = Turn1 %>%    
  group(n= 100, method= 'greedy') %>%    
  dplyr::summarise(time= mean(time,na.rm=T), HR1 = mean(HR1,na.rm=T), HR2 = mean(HR2,na.rm=T), Resp1 =  mean(Resp1,na.rm=T), Resp2 = mean(Resp2,na.rm=T)) 

Conv = Conv1 %>%    
  group(n= 100, method= 'greedy') %>%    
  dplyr::summarise(time= mean(time,na.rm=T), HR1 = mean(HR1,na.rm=T), HR2 = mean(HR2,na.rm=T), Resp1 =  mean(Resp1,na.rm=T), Resp2 = mean(Resp2,na.rm=T)) 

Sync$condition = "synchronous"
Turn$condition = "turntaking"
Conv$condition = "conversation"

df = rbind(Sync, Turn, Conv)

#Rescale (bør nok gøres for hver condition i stedet for samlet ligesom når vi downsampler)
df$Resp1S=scale(df$Resp1)  
df$Resp2S=scale(df$Resp2)  
df$HR1S=scale(df$HR1) 
df$HR2S=scale(df$HR2)

#removing outliers
removeOuts <- function(ts,threshold){
  ts[ts > (mean(ts,na.rm=T) + (threshold*sd(ts,na.rm=T))) |
       ts < (mean(ts,na.rm=T) - (threshold*sd(ts,na.rm=T)))] =  mean(ts,na.rm=T)   
  return(ts)}

threshold=2.5 
#removing outliers from HR data
df$HR1S=removeOuts(df$HR1S,threshold)
df$HR2S=removeOuts(df$HR2S, threshold)
#removing outliers for resp data
df$Resp1S=removeOuts(df$Resp1S, threshold)
df$Resp2S=removeOuts(df$Resp2S, threshold)

#making subsets (tror overhovedet ikke vi skal samle det på noget tidspunkt men bare holde dem adskilt hele vejen)
sync = subset(df, condition == "synchronous")
turn = subset(df, condition == "turntaking")
conv = subset(df, condition == "conversation")

#pretty plots
syncHR = ggplot(sync, aes(time, HR1S)) + geom_line() + geom_line(aes(time, HR2S, color = "red"))
syncResp = ggplot(sync, aes(time, Resp1S)) + geom_line() + geom_line(aes(time, Resp2S, color = "red"))

turnHR = ggplot(turn, aes(time, HR1S)) + geom_line() + geom_line(aes(time, HR2S, color = "red"))
turnResp = ggplot(turn, aes(time, Resp1S)) + geom_line() + geom_line(aes(time, Resp2S, color = "red"))

convHR = ggplot(conv, aes(time, HR1S)) + geom_line() + geom_line(aes(time, HR2S, color = "red"))
convResp = ggplot(conv, aes(time, Resp1S)) + geom_line() + geom_line(aes(time, Resp2S, color = "red"))

grid.arrange(syncHR, syncResp, turnHR, turnResp, convHR, convResp)
```
Running CRQA
```{r}
##for turn taking condition
par = list(lgM =  50, steps = seq(1, 6, 1),  radiusspan = 100,  radiussample = 40, normalize = 0,  rescale = 0,  mindiagline = 2,  
minvertline = 2,  tw = 0,  whiteline = FALSE,  recpt = FALSE,  fnnpercent = 10,  typeami = "mindip")


ans = optimizeParam(turn$Resp1S, turn$Resp2S, par, min.rec = 3.5, max.rec = 4.5)
ans

Results=crqa(turn$Resp1S, turn$Resp2S, delay=ans$delay, embed=ans$emddim, radius=ans$radius,normalize=0,rescale=0,mindiagline = 2,minvertline = 2) 

Results

#Creating plot
RP = Results$RP
RP = matrix(as.numeric(RP), nrow = ncol(RP))
cols = c("white", "blue4")
image(RP, xlab = "", ylab = "", col = cols)
```

```{r}
##for conversation condition
par = list(lgM =  50, steps = seq(1, 6, 1),  radiusspan = 100,  radiussample = 40, normalize = 0,  rescale = 0,  mindiagline = 2,  
minvertline = 2,  tw = 0,  whiteline = FALSE,  recpt = FALSE,  fnnpercent = 10,  typeami = "mindip")


ans = optimizeParam(conv$Resp1S, conv$Resp2S, par, min.rec = 3.5, max.rec = 4.5)
ans

Results=crqa(conv$Resp1S, conv$Resp2S, delay=ans$delay, embed=ans$emddim, radius=ans$radius,normalize=0,rescale=0,mindiagline = 2,minvertline = 2) 

Results

#Creating plot
RP = Results$RP
RP = matrix(as.numeric(RP), nrow = ncol(RP))
cols = c("white", "blue4")
image(RP, xlab = "", ylab = "", col = cols)
```

### Systematically pre-process the data
- Loop through all the files (either with a loop or with a function), check which files should be excluded, if any, and save the pre-processed time-series. Tip: plot and visually inspect the data to figure out which should be excluded.
- Run crqa on all the pre-processed time-series and save the output (don't forget to add columns with study, group, condition and trial). Tip: remember to first assess optimal parameters (dimensions, delay, radius) across all timeseries. Tip: it will often fail, just take whatever parameters you get, select optimal across timeseries parameters and run crqa on all timeseries with those. Tip: double check the rr. When I ran the loop, I got very low rr, so I adjusted the radius until the average of rr across all pairs was approx. 4%.

radius = median(radius) + 1.2 seems to be good according to Riccardo

```{r preprocessing function}
#####
#BIG FAT FUNCTION
#####

#dependency for the preproz function
removeOuts <- function(ts,threshold){
  ts[ts > (mean(ts,na.rm=T) + (threshold*sd(ts,na.rm=T))) |
       ts < (mean(ts,na.rm=T) - (threshold*sd(ts,na.rm=T)))] =  mean(ts,na.rm=T)   
  return(ts)}
threshold=2.5 

#function to downsample, rescale, remove outliers, print plots for HR and respiration as well as finding optimal parameters for crqa. Outputs a dataframe and prints plots
preproz = function(filename, graphs = T, noOutliers = T){ #requires the removeOuts function and a set threshold
  folder = "CleanData/"
  df = read_csv(paste(folder, filename, sep=""))
   
  #Downsample
  df = df %>%    
  group(n= 100, method= 'greedy') %>%    
  dplyr::summarise(time= mean(time,na.rm=T), HR1 = mean(HR1,na.rm=T), HR2 = mean(HR2,na.rm=T), Resp1 =  mean(Resp1,na.rm=T), Resp2 = mean(Resp2,na.rm=T)) 
   
  if(noOutliers == T) {
  #Removing outliers
  df$HR1=removeOuts(df$HR1,threshold)
  df$HR2=removeOuts(df$HR2, threshold)
  df$Resp1=removeOuts(df$Resp1, threshold)
  df$Resp2=removeOuts(df$Resp2, threshold)
  }
  
  #Rescale
  df$Resp1S=scale(df$Resp1)  
  df$Resp2S=scale(df$Resp2)  
  df$HR1S=scale(df$HR1) 
  df$HR2S=scale(df$HR2)
  
  #Adding study identification colomns
  df$study = str_extract(filename, "Study(\\d)") 
  df$group = str_extract(filename, "G(\\d+)")
  df$trial = str_extract(filename, "T(\\d)")
  df$condition = gsub('.{4}$', '', strsplit(filename, "_")[[1]][4])
  df$filename = filename
  
  ###Calculating optimal parameters
  #setting parameters
  par = list(lgM =  50, steps = seq(1, 6, 1),  radiusspan = 100,  radiussample = 40, normalize = 0,  rescale = 0,  mindiagline = 2,  
minvertline = 2,  tw = 0,  whiteline = FALSE,  recpt = FALSE,  fnnpercent = 10,  typeami = "mindip")

  #getting the optimal parameters and saving to opt_paramHR/Resp. Using try so it doesn't crash if there is an error
  
  #First getting parameters for HR data
  opt_paramHR = try(optimizeParam(df$HR1S, df$HR2S, par, min.rec = 2, max.rec = 8))
  #if the optimize function succeeded, save the results to the dataframe - if not, put NAs 
  if (length(opt_paramHR) > 2) {
    #need to unlist the parameters otherwise they can't be used for later calculations (no idea why it makes them a list in the first place)
   df$optRadiusHR = unlist(opt_paramHR[1])
   df$optEmbdimHR = unlist(opt_paramHR[2])
   df$optDelayHR = unlist(opt_paramHR[3])
   } else {
   df$optRadiusHR = NA
   df$optEmbdimHR = NA
   df$optDelayHR = NA
   }

  #Now for respiration data
  opt_paramResp = try(optimizeParam(df$Resp1S, df$Resp2S, par, min.rec = 2, max.rec = 8))
  #if the optimize function succeeded, save the results to the dataframe - if not, put NAs 
  if (length(opt_paramResp) > 2) {
    df$optRadiusResp = unlist(opt_paramResp[1])
    df$optEmbdimResp = unlist(opt_paramResp[2])
    df$optDelayResp = unlist(opt_paramResp[3])
    } else {
    df$optRadiusResp = NA
    df$optEmbdimResp = NA
    df$optDelayResp = NA
    }

  #creating new csv file with the new columns
  name = str_extract(filename, '.*(?=\\.csv)') #removing .csv from filename
  name = paste(name, "PROCESSED.csv", sep = '_')
  #creating new folder to store the files in 
  dir.create("preprocessed", showWarnings = FALSE) #stops warnings if folder already exists
  #writing file to the new folder
  write.csv(df, file.path("preprocessed", name), row.names=FALSE)

  if(graphs == T) {
  #Adding plots
  HR = ggplot(df, aes(time, HR1S)) + 
    geom_line() + 
    geom_line(aes(time, HR2S, color = "red")) + 
    ggtitle(filename) +
    theme(legend.position = "none")
  Resp = ggplot(df, aes(time, Resp1S)) + 
    geom_line() + 
    geom_line(aes(time, Resp2S, color = "red")) + 
    ggtitle(filename) +
    theme(legend.position = "none")

  #printing the arranged plots to console
  grid.arrange(HR, Resp)
  #grid.arrange can't be saved but will only print. Using arrangeGrob to save to variable and then to disk
  plots = arrangeGrob(HR, Resp) #generates g
  
  #creating a unique name for each plot based on the filename
  plotname = str_extract(filename, '.*(?=\\.csv)') #removing .csv from filename
  plotname = paste(plotname, "PLOT.png", sep = '_')
  #creating new folder to store the files in 
  dir.create("plots", showWarnings = FALSE) #stops warnings if folder already exists
  #writing file to the new folder
  #ggsave(plotname, plot = plots, path = "plots/")
  ggsave(file=plotname, plots, path = "plots/")
  }
  
  #Return df
  return(df)

}

testout = preproz("Study2_G5_T3_Conversation.csv")
testout = bind_rows(testout)

files = list.files(path = "CleanData/", pattern = "*.csv")
processed = lapply(files, preproz)
processed = bind_rows(processed)

#Creating new column with optimal values
processed = processed %>% 
  mutate(opt_dimHR = median(processed$optEmbdimHR, na.rm = T), 
         opt_delayHR = median(processed$optDelayHR, na.rm = T), 
         opt_radHR = median(processed$optRadiusHR, na.rm = T),
         opt_dimResp = median(processed$optEmbdimResp, na.rm = T), 
         opt_delayResp = median(processed$optDelayResp, na.rm = T), 
         opt_radResp = median(processed$optRadiusResp, na.rm = T))

#write.csv(processed, file = "processedData.csv")

#removing files 1,2, 4, 5 as well as all selfpaced conditions

###REMOMVE 1, 2, 4, 5
```

```{r}

processed = read.csv("processedData.csv")

optParams = processed %>%
  group_by(filename) %>%
  summarise(optEmbdimHR = median(optEmbdimHR, na.rm = T), 
         optDelayHR = median(optDelayHR, na.rm = T), 
         optRadiusHR = median(optRadiusHR, na.rm = T),
         optEmbdimResp = median(optEmbdimResp, na.rm = T), 
         optDelayResp = median(optDelayResp, na.rm = T), 
         optRadiusResp = median(optRadiusResp, na.rm = T)) %>%
  mutate(opt_dimHR = median(optEmbdimHR, na.rm = T), 
         opt_delayHR = median(optDelayHR, na.rm = T), 
         opt_radHR = median(optRadiusHR, na.rm = T),
         opt_dimResp = median(optEmbdimResp, na.rm = T), 
         opt_delayResp = median(optDelayResp, na.rm = T), 
         opt_radResp = median(optRadiusResp, na.rm = T))

optParams
#det er noget pis


#function to perform crqa on all datasets USE THE PROCESSED DATASETS 

rqaFun = function(filename, shuf = FALSE){ #making a function which applies the optimal parameters and then saves the rqa results
  folder = "preprocessed/"
  df = read.csv(paste(folder, filename, sep=""))
  

  if(shuf == TRUE) {
    sampleList = c("Resp1S", "Resp2S", "HR1S", "HR2S")
    df = df[, colnames(df) %in% sampleList] %>% #select columns to sample 
    lapply(. , function(x) sample(x)) %>% 
    cbind(. , df[,! colnames(df) %in% sampleList]) #bind with remaining columns
 
  }
  
  #crqa for HR data
  result = try(crqa(df$HR1S, df$HR2S, embed = optParams$opt_dimHR[1], delay = optParams$opt_delayHR[1], radius = optParams$opt_radHR[1], normalize = 0,  rescale = 0,  mindiagline = 2,  minvertline = 2,  tw = 0,  whiteline = FALSE,  recpt = FALSE))
  if (length(result) > 1){
    df$RR.HR = unlist(result[1])
    df$DET.HR = unlist(result[2])
    df$NRLINE.HR = unlist(result[3])
    df$maxL.HR = unlist(result[4])
    df$L.HR = unlist(result[5])
    df$ENTR.HR = unlist(result[6])
    df$rENTR.HR = unlist(result[7])
    df$LAM.HR = unlist(result[8])
    df$TT.HR = unlist(result[9])
  } else {
    df$RR.HR = NA
    df$DET.HR = NA
    df$NRLINE.HR = NA
    df$maxL.HR = NA
    df$L.HR = NA
    df$ENTR.HR = NA
    df$rENTR.HR = NA
    df$LAM.HR = NA
    df$TT.HR = NA
  }
  
  #for respiration data
    result = try(crqa(df$Resp1S, df$Resp2S, embed = optParams$opt_dimResp[1], delay = optParams$opt_delayResp[1], radius = optParams$opt_radResp[1], normalize = 0,  rescale = 0,  mindiagline = 2,  minvertline = 2,  tw = 0,  whiteline = FALSE,  recpt = FALSE))
  if (length(result) > 1){
    df$RR.Resp = unlist(result[1])
    df$DET.Resp = unlist(result[2])
    df$NRLINE.Resp = unlist(result[3])
    df$maxL.Resp = unlist(result[4])
    df$L.Resp = unlist(result[5])
    df$ENTR.Resp = unlist(result[6])
    df$rENTR.Resp = unlist(result[7])
    df$LAM.Resp = unlist(result[8])
    df$TT.Resp = unlist(result[9])
  } else {
    df$RR.Resp = NA
    df$DET.Resp = NA
    df$NRLINE.Resp = NA
    df$maxL.Resp = NA
    df$L.Resp = NA
    df$ENTR.Resp = NA
    df$rENTR.Resp = NA
    df$LAM.Resp = NA
    df$TT.Resp = NA
  }
  
  
  return(df)
}
test = rqaFun("Study2_G5_T3_Conversation_PROCESSED.csv")
test = bind_rows(test)

preprocessed_files = list.files(path = "preprocessed/", pattern = "*.csv")
final_df = lapply(preprocessed_files, rqaFun)
final_df = bind_rows(final_df)

summa = function(df){
summarised_df = df  %>%
  group_by(filename) %>%
  summarise(RR.HR = mean(RR.HR, na.rm = T), 
         DET.HR = mean(DET.HR, na.rm = T), 
         NRLINE.HR = mean(NRLINE.HR, na.rm = T),
         maxL.HR = mean(maxL.HR, na.rm = T), 
         L.HR = mean(L.HR, na.rm = T), 
         ENTR.HR = mean(ENTR.HR, na.rm = T),
         rENTR.HR = mean(rENTR.HR, na.rm = T),
         LAM.HR = mean(LAM.HR, na.rm = T),
         TT.HR = mean(TT.HR, na.rm = T),
         
         RR.Resp = mean(RR.Resp, na.rm = T), 
         DET.Resp = mean(DET.Resp, na.rm = T), 
         NRLINE.Resp = mean(NRLINE.Resp, na.rm = T),
         maxL.Resp = mean(maxL.Resp, na.rm = T), 
         L.Resp = mean(L.Resp, na.rm = T), 
         ENTR.Resp = mean(ENTR.Resp, na.rm = T),
         rENTR.Resp = mean(rENTR.Resp, na.rm = T),
         LAM.Resp = mean(LAM.Resp, na.rm = T),
         TT.Resp = mean(TT.Resp, na.rm = T),

         condition = condition[1],
         group = group[1],
         trial = trial[1],
         study = study[1])
  return(summarised_df)
}
      ##do the same for shuf to compare


#write.csv(final_df, "final_df.csv")

```


### Creating controls: shuffled controls
 - loop through all pairs and conditions
 - shuffle the timeseries (take a timeseries and rearrange its values in a random order). Tip check the sample() function
 - run crqa and save the output. NB. which delay, embed, radius parameters should you use?
 - statistically compare the crqa indexes in real and shuffled pairs
 
```{r}
#test
shuf = rqaFun("Study2_G5_T3_Conversation_PROCESSED.csv", shuf = T)
nonshuf = rqaFun("Study2_G5_T3_Conversation_PROCESSED.csv", shuf = F)

shuff = function(df){
    sampleList = c("Resp1S", "Resp2S", "HR1S", "HR2S")
    df_sample = df[, colnames(df) %in% sampleList] %>% #select columns to sample 
    lapply(. , function(x) sample(x)) %>% 
    cbind(. , df[,! colnames(df) %in% sampleList]) #bind with remaining columns
    }

test = read.csv("preprocessed/Study2_G5_T3_Conversation_PROCESSED.csv")
test2 = shuff(test)

#which parameters to use?? - using the same as for the non-shuffled to keep the values comparable (since the values are highly dependent on embdim)
preprocessed_files = list.files(path = "preprocessed/", pattern = "*.csv")

shuffled_df = lapply(preprocessed_files, rqaFun, shuf = T)
shuffled_df = bind_rows(shuffled_df)
shufff = summa(shuffled_df)
#write.csv(shuffled_df, "shuffled_df.csv")

```
 
### TRICKY! Creating controls: surrogate pair controls
 - Per each real pair, identify at least one surrogate pair (matching one of the participants, with somebody doing the same task, but in a different pair). Tip: Celine will share a commented script
 - Run crqa on all the surrogate pairs and save the output. NB. which delay, embed, radius parameters should you use?
 - Test whether crqa shows a difference between real and surrogate pairs
 
- 4 different ways to make surrogate pairs.. 

#RQA extractor
```{r}
#defining a function to extract rqa values 
rqa_extractor = function(t1, t2, embed, delay, radius){ #making a function which applied the optimal parameters and then saves the rqa results 

  result = try(crqa(t1, t2, embed = embed, delay = delay, radius = radius, normalize = 0, rescale = 0, mindiagline = 2, minvertline = 2, tw = 0, whiteline = FALSE, recpt = FALSE)) 
  if (length(result) > 1){ 
    results_df = data.frame(RR = result[1], DET = result[2], NRLINE = result[3], maxL = result[4], L = result[5], ENTR = result[6], rENTR = result[7], LAM = result[8], TT = result[9]) 
  } 
  else { results_df = data.frame(RR = NA, DET = NA, NRLINE = NA, maxL = NA, L = NA, ENTR = NA, rENTR = NA, LAM = NA, TT = NA) 
  } 
  return(results_df) 
}



#KØR ALT IGEN WUHU
```


#Surrogate pairs (Kenneths kode)
```{r}
i = 1 #Loop for surrogate pairs 
all_dat = read.csv("final_df.csv")

for (g in seq(unique(all_dat$group))){ #loop through all the groups 
  g1 = unique(all_dat$group)[g]
  non_g1 = unique(all_dat$group)[unique(all_dat$group)!= g1] #a list of groups which does not include g1
  g2 = sample(non_g1)[1] #randomly select a group which is in the non_g1 vector
  print(g1)

  for (c in unique(all_dat$condition)){ #looping through conditions 
    temp1 = subset(all_dat, group == g1 & condition == c) #e.g. the first group in condition 'turntaking
    temp2 = subset(all_dat, group == g2 & condition == c) #e.g. the second group in condition 'turntaking

      #doing rqa
    result_Resp = rqa_extractor(t1 = temp1$Resp1S, t2 = temp2$Resp2S, embed = optParams$opt_dimResp, 
                                delay = optParams$opt_delayResp, radius = optParams$opt_radResp)

    result_HR = rqa_extractor(t1 = temp1$HR1S, t2 = temp2$HR2S, embed = optParams$opt_dimHR, 
                              delay = optParams$opt_delayHR, radius = optParams$opt_radHR)

    colnames(result_Resp) = paste(colnames(result_Resp), "Resp", sep = ".")
    colnames(result_HR) = paste(colnames(result_HR), "HR", sep = ".")
    
    temp = cbind(result_Resp, result_HR)
    temp$condition = c
    temp$group1 = g1
    temp$group2 = g2

    if (i == 1){ #create df
      surPair_rqa = temp
      i = 2 #if you have already done this then don't do it again
    } else { #append to df
      surPair_rqa = rbind(surPair_rqa, temp)
    }
  print(c)
  }
}

#write.csv(surPair_rqa, "surPairs.csv")
```


#testing the effect of surrogate pairs
```{r}
#reading original data sets
og_df = read.csv("final_df.csv")
shuf_df = read.csv("shuffled_df.csv")
surPair_rqa = read.csv("surPairs.csv")
surPair_rqa$X = NULL

sum_og_df = summa(og_df)
sum_shuf_df = summa(shuf_df)


sum_shuf_df$type = "Shuffled"
sum_shuf_df$trial = NULL
sum_shuf_df$study = NULL
sum_shuf_df$filename = NULL
sum_og_df$type = "Original"
sum_og_df$trial = NULL
sum_og_df$study = NULL
sum_og_df$filename = NULL
surPair_rqa$type = "Surrogate"

surPair_rqa$group = surPair_rqa$group1
surPair_rqa = select(surPair_rqa, -c(group1, group2))

final_df = rbind(sum_shuf_df, sum_og_df, surPair_rqa)

final_df$type = as.factor(final_df$type)
final_df$type = relevel(final_df$type, ref = "Shuffled")

#write.csv(final_df, "final_df.csv")
```

#modelz
```{r}
mRR = lmer(RR.HR ~ type + (1|group), final_df)
mDET = lmer(DET.HR ~ type + (1|group), final_df) 
mNRLINE = lmer(NRLINE.HR ~ type + (1|group), final_df) 
mTT = lmer(TT.HR ~ type + (1|group), final_df)
mL = lmer(L.HR ~ type + (1|group), final_df)
mMaxL = lmer(maxL.HR ~ type + (1|group), final_df)
mENTR = lmer(ENTR.HR ~ type + (1|group), final_df) 
mrENTR = lmer(rENTR.HR ~ type + (1|group), final_df) 
mLAM = lmer(LAM.HR ~ type + (1|group), final_df) 




summary(mRR)
summary(mDET)  #significant!!!!!!!!!!1111
summary(mTT)  #also significant!!11!1!1!
summary(mL)  #woohoo!!
summary(mMaxL) #helzz yeah
summary(mNRLINE)
summary(mENTR) #yep
summary(mrENTR) #yepyep
summary(mLAM) #yepyepyep

mRR = lmer(RR.Resp ~ type  + (1|group), final_df)
mDET = lmer(DET.Resp ~ type + (1|group), final_df)
mTT = lmer(TT.Resp ~ type + (1|group), final_df)
mL = lmer(L.Resp ~ type + (1|group), final_df)
mMaxL = lmer(maxL.Resp ~ type + (1|group), final_df)
mNRLINE = lmer(NRLINE.Resp ~ type + (1|group), final_df) 
mENTR = lmer(ENTR.Resp ~ type + (1|group), final_df) 
mrENTR = lmer(rENTR.Resp ~ type + (1|group), final_df) 
mLAM = lmer(LAM.Resp ~ type + (1|group), final_df) 



summary(mRR)
summary(mDET) #signifz
summary(mTT) #sniiii
summary(mL) #extra snugiz
summary(mMaxL) #woopsz
summary(mNRLINE) #yas
summary(mENTR) #yas
summary(mrENTR) #yas
summary(mLAM) #helt sikkert

r.squaredGLMM(m2)
```


### Testing effects of conditions
 - make a (probably underpowered) mixed model testing effects of the different conditions on heart rate and respiration coordination
 - N.B: would it make sense to include surrogate pairs? and if so how? what would that tell you?
 
 
```{r}
mRR = lmer(RR.HR ~ condition + (1|group), final_df)
mDET = lmer(DET.HR ~ condition + (1|group), final_df) 
mTT = lmer(TT.HR ~ condition + (1|group), final_df)
mL = lmer(L.HR ~ condition + (1|group), final_df)
mMaxL = lmer(maxL.HR ~ condition + (1|group), final_df)
mNRLINE = lmer(NRLINE.HR ~ condition + (1|group), final_df) 
mENTR = lmer(ENTR.HR ~ condition + (1|group), final_df) 
mrENTR = lmer(rENTR.HR ~ condition + (1|group), final_df) 
mLAM = lmer(LAM.HR ~ condition + (1|group), final_df) 



summary(mRR)
summary(mDET)
summary(mTT) 
summary(mL)  
summary(mMaxL)
summary(mNRLINE) #synchronous
r.squaredGLMM(mNRLINE)
summary(mENTR)
summary(mrENTR)
summary(mLAM)



mRR = lmer(RR.Resp ~ condition  + (1|group), final_df)
mDET = lmer(DET.Resp ~ condition + (1|group), final_df)
mTT = lmer(TT.Resp ~ condition + (1|group), final_df)
mL = lmer(L.Resp ~ condition + (1|group), final_df)
mMaxL = lmer(maxL.Resp ~ condition + (1|group), final_df)
mNRLINE = lmer(NRLINE.Resp ~ condition + (1|group), final_df) 
mENTR = lmer(ENTR.Resp ~ condition + (1|group), final_df) 
mrENTR = lmer(rENTR.Resp ~ condition + (1|group), final_df) 
mLAM = lmer(LAM.Resp ~ condition + (1|group), final_df) 



summary(mRR) #turntaking
r.squaredGLMM(mRR)
summary(mDET) 
summary(mTT) 
summary(mL) 
summary(mMaxL) 
summary(mNRLINE)
summary(mENTR)
summary(mrENTR)
summary(mLAM)

```

### Effects of respiration coordination on heart rate coordination
 - describe how you would test those.
 - Optional: run the models and report them
 
```
